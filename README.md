# Agentic Bias Checkpoint Auditor

A powerful tool to identify where bias originates in your ML pipeline by analyzing three critical checkpoints: **Data â†’ Features â†’ Model**.

## ğŸ¯ Overview

The Bias Auditor uses four specialized AI agents to analyze your ML pipeline:

1. **Data Auditor** - Detects underrepresentation, missing groups, and label imbalance
2. **Feature Forensics** - Identifies proxy features and encoding risks
3. **Model Behavior** - Measures fairness gaps and counterfactual sensitivity
4. **Bias Aggregator** - Determines primary bias origin and recommends fixes

### âœ¨ Enhanced Features

- **ğŸ” Observability**: Structured logging, execution tracing, and metrics collection
- **ğŸ› ï¸ Custom Tools**: Specialized bias detection tools (SubgroupAnalysis, ProxyDetector, FairnessMetrics, CounterfactualGenerator)
- **ğŸŒ MCP Integration**: Bias pattern knowledge base via MCP server
- **ğŸ¤– Gemini AI**: LLM-powered explanations and recommendations using Google's Gemini API

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- pip package manager

### Installation

1. **Clone and navigate to the project directory:**
   ```bash
   cd bias-auditor
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure Gemini API (Optional but Recommended):**
   ```bash
   # Copy the example env file
   copy .env.example .env
   
   # Edit .env and add your Gemini API key
   # GEMINI_API_KEY=your_api_key_here
   ```
   
   Get your API key from: https://aistudio.google.com/app/apikey

### Running the Application

1. **(Optional) Start the MCP Server:**
   ```bash
   cd mcp_server
   python server.py
   ```
   
   The MCP server provides bias pattern resources at `http://localhost:8001`

2. **Start the backend API:**
   ```bash
   cd backend
   python main.py
   ```
   
   The API will be available at `http://localhost:8000`

3. **Start the frontend (in a new terminal):**
   ```bash
   cd frontend
   streamlit run app.py
   ```
   
   The UI will open in your browser at `http://localhost:8501`

## ğŸ“‹ Usage

### 1. Prepare Your Data

You need three files:

- **raw_data.csv** - Raw training data with:
  - Sensitive attributes (e.g., gender, race, age)
  - Target column (binary: 0/1)
  - Other features

- **processed_features.csv** - Engineered features (row-aligned with raw data)

- **model.pkl** - Pickled scikit-learn compatible model

### 2. Run an Audit

1. Navigate to "New Audit" in the sidebar
2. Upload your three files
3. Select target column and sensitive attributes
4. Adjust thresholds (optional)
5. Click "Start Audit"

### 3. View Results

1. Navigate to "Run History"
2. Select your run
3. View the bias origin verdict
4. Explore detailed analysis in tabs:
   - **Data** - Subgroup statistics and label distribution
   - **Features** - Proxy features and encoding risks
   - **Model** - Fairness metrics and counterfactual tests
   - **Recommendations** - Actionable fixes

## ğŸ” What It Detects

### Data Checkpoint
- âŒ Underrepresented groups (<5% of data)
- âŒ Missing expected demographic categories
- âŒ Severe label imbalance (ratio >4:1)

### Feature Checkpoint
- âŒ Proxy features (high correlation with sensitive attributes)
- âŒ Target leakage
- âŒ Sparse one-hot encoding issues

### Model Checkpoint
- âŒ Demographic parity violations (acceptance rate gaps)
- âŒ Equal opportunity violations (TPR gaps)
- âŒ Equalized odds violations (TPR + FPR gaps)
- âŒ Counterfactual sensitivity

## ğŸ“Š Example Test Data

To test the system, you can generate synthetic biased data:

```bash
python scripts/generate_test_data.py
```

This creates:
- `test_data/raw_data.csv`
- `test_data/processed_features.csv`
- `test_data/model.pkl`

Upload these files to see the auditor in action!

## ğŸ—ï¸ Architecture

```
bias-auditor/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ database.py          # SQLite database
â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”œâ”€â”€ orchestrator.py      # Agent coordination with observability
â”‚   â”œâ”€â”€ observability.py     # Logging, tracing, metrics
â”‚   â”œâ”€â”€ gemini_agent.py      # Gemini AI integration
â”‚   â”œâ”€â”€ mcp_client.py        # MCP client
â”‚   â”œâ”€â”€ utils.py             # Shared utilities
â”‚   â”œâ”€â”€ agents/              # Specialized agents
â”‚   â”‚   â”œâ”€â”€ data_auditor.py
â”‚   â”‚   â”œâ”€â”€ feature_forensics.py
â”‚   â”‚   â”œâ”€â”€ model_behavior.py
â”‚   â”‚   â””â”€â”€ bias_aggregator.py
â”‚   â””â”€â”€ tools/               # Custom bias detection tools
â”‚       â”œâ”€â”€ base.py          # Tool framework
â”‚       â””â”€â”€ bias_detector.py # Bias detection tools
â”œâ”€â”€ mcp_server/              # MCP server for bias patterns
â”‚   â”œâ”€â”€ server.py            # HTTP server
â”‚   â””â”€â”€ resources.py         # Bias pattern knowledge base
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py               # Streamlit UI
â”œâ”€â”€ data/                    # Run artifacts (auto-created)
â”‚   â”œâ”€â”€ logs/                # Structured logs
â”‚   â”œâ”€â”€ traces/              # Execution traces
â”‚   â””â”€â”€ metrics/             # Performance metrics
â””â”€â”€ requirements.txt
```

### ğŸ“ Course Concepts Demonstrated

This project demonstrates **5 key concepts** from the Agentic AI course:

1. **Sequential Agents** - Four agents execute in sequence (Data â†’ Features â†’ Model â†’ Aggregator)
2. **State Management** - SQLite database tracks run status and configuration
3. **Observability** - Structured logging, execution tracing, and metrics collection
4. **Custom Tools** - Specialized tools for bias detection (SubgroupAnalysis, ProxyDetector, etc.)
5. **LLM Integration (Gemini API)** - AI-powered explanations and recommendations

## ğŸ“– API Documentation

Once the backend is running, visit:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### Key Endpoints

- `POST /runs` - Create new audit run
- `GET /runs` - List all runs
- `GET /runs/{run_id}` - Get run details
- `GET /runs/{run_id}/artifacts/{type}` - Get JSON artifact
- `GET /runs/{run_id}/plots/{name}` - Get plot image

## âš™ï¸ Configuration

Default fairness thresholds (adjustable in UI):

```json
{
  "demographic_parity_diff_threshold": 0.1,
  "equal_opportunity_diff_threshold": 0.1,
  "equalized_odds_diff_threshold": 0.1,
  "min_group_proportion_threshold": 0.05,
  "min_support_for_metrics": 30,
  "proxy_corr_threshold": 0.3,
  "counterfactual_change_threshold": 0.1,
  "label_imbalance_ratio_threshold": 4.0
}
```

## ğŸ”§ Troubleshooting

### Backend won't start
- Check if port 8000 is available
- Ensure all dependencies are installed: `pip install -r requirements.txt`

### Frontend can't connect to backend
- Verify backend is running at `http://localhost:8000`
- Check CORS settings in `backend/main.py`

### Model loading fails
- Ensure model is scikit-learn compatible
- Model must have `predict()` and `predict_proba()` methods

## ğŸ“ Limitations (MVP)

- Binary classification only
- Scikit-learn compatible models only
- Local filesystem storage (not production-ready for scale)
- Synchronous processing (no async workers)

## ğŸ›£ï¸ Roadmap

Future enhancements:
- Multi-class classification support
- Async processing with Celery
- PostgreSQL support
- Authentication & authorization
- Batch processing
- Export reports as PDF

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ“§ Support

For issues or questions, please open a GitHub issue.
